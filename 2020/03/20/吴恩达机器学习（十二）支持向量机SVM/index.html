<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="吴恩达机器学习," />










<meta name="description" content="十二、支持向量机 (Support Vector Machines)12.1 优化目标与逻辑回归和神经网络相比，支持向量机，或者简称SVM，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。 也属于监督学习算法 为了描述支持向量机，事实上，我们从逻辑回归开始展示我们如何一点一点修改来得到本质上的支持向量机。 如前所述，逻辑回归假设如下：  $h( z )&#x3D;\frac{1}{1+e^{-\">
<meta property="og:type" content="article">
<meta property="og:title" content="吴恩达机器学习（十二）支持向量机SVM">
<meta property="og:url" content="http://yoursite.com/2020/03/20/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/index.html">
<meta property="og:site_name" content="天天的个人博客">
<meta property="og:description" content="十二、支持向量机 (Support Vector Machines)12.1 优化目标与逻辑回归和神经网络相比，支持向量机，或者简称SVM，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。 也属于监督学习算法 为了描述支持向量机，事实上，我们从逻辑回归开始展示我们如何一点一点修改来得到本质上的支持向量机。 如前所述，逻辑回归假设如下：  $h( z )&#x3D;\frac{1}{1+e^{-\">
<meta property="og:image" content="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B1%5D.png">
<meta property="og:image" content="http://yoursite.com/images/1584696526870.png">
<meta property="og:image" content="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B5%5D.png">
<meta property="og:image" content="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B6%5D.png">
<meta property="og:image" content="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B7%5D.png">
<meta property="og:image" content="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B8%5D.png">
<meta property="og:image" content="http://yoursite.com/images/1584696618394.png">
<meta property="og:image" content="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B12%5D.png">
<meta property="og:image" content="http://yoursite.com/images/1584696727001.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200216202054167.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MDgyMTQ4,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200216202109997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MDgyMTQ4,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200216202139908.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MDgyMTQ4,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cDovL3d3dy5ob2xlaG91c2Uub3JnL21sY2xhc3MvMTJfU3VwcG9ydF9WZWN0b3JfTWFjaGluZXNfZmlsZXMvSW1hZ2UlMjBbNDFdLnBuZw?x-oss-process=image/format,png">
<meta property="og:image" content="http://yoursite.com/images/1584696858952.png">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200216202218233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MDgyMTQ4,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://imgconvert.csdnimg.cn/aHR0cDovL3d3dy5ob2xlaG91c2Uub3JnL21sY2xhc3MvMTJfU3VwcG9ydF9WZWN0b3JfTWFjaGluZXNfZmlsZXMvSW1hZ2UlMjBbNDldLnBuZw?x-oss-process=image/format,png">
<meta property="og:image" content="f:%5Cworkspace%5Cpython%5C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%5C%E5%90%B4%E6%81%A9%E8%BE%BE%5Ctiantian152-Coursera-ML-AndrewNg-Notes-master%5CCoursera-ML-AndrewNg-Notes%5Cimages%5C3d8959d0d12fe9914dc827d5a074b564.jpg">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200216201536961.png">
<meta property="og:image" content="http://yoursite.com/images/1584696927439.png">
<meta property="article:published_time" content="2020-03-20T09:04:00.000Z">
<meta property="article:modified_time" content="2020-03-20T09:37:57.300Z">
<meta property="article:author" content="tiantian">
<meta property="article:tag" content="吴恩达机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B1%5D.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/03/20/吴恩达机器学习（十二）支持向量机SVM/"/>





  <title>吴恩达机器学习（十二）支持向量机SVM | 天天的个人博客</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">天天的个人博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/20/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="tiantian">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="天天的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">吴恩达机器学习（十二）支持向量机SVM</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-03-20T17:04:00+08:00">
                2020-03-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/03/20/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/03/20/吴恩达机器学习（十二）支持向量机SVM/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="十二、支持向量机-Support-Vector-Machines"><a href="#十二、支持向量机-Support-Vector-Machines" class="headerlink" title="十二、支持向量机 (Support Vector Machines)"></a>十二、支持向量机 (Support Vector Machines)</h2><h3 id="12-1-优化目标"><a href="#12-1-优化目标" class="headerlink" title="12.1 优化目标"></a>12.1 优化目标</h3><p>与<strong>逻辑回归</strong>和<strong>神经网络</strong>相比，<strong>支持向量机</strong>，或者简称<strong>SVM</strong>，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。</p>
<p>也属于监督学习算法</p>
<p>为了描述支持向量机，事实上，我们从逻辑回归开始展示我们如何一点一点修改来得到本质上的支持向量机。</p>
<p>如前所述，逻辑回归假设如下：  $h( z )=\frac{1}{1+e^{-\theta^Tx}}​$</p>
<p>图像<img src="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B1%5D.png" alt="img"></p>
<p>为了解释数学，我们使用上面定义的 $z = \theta^{T}x ​$</p>
<p>我们希望逻辑回归做什么？</p>
<ul>
<li>我们有一个y = 1的例子</li>
<li>我们希望当 $h_\theta(x)​$ 趋近 1<ul>
<li>因为我们想要正确地将此样本分类，这就意味着当 $h_\theta(x)​$趋近于1时，$z = \theta^{T}x ​$ 应当远大于0</li>
</ul>
</li>
<li>当$h_\theta(x)​$ 趋近 0<ul>
<li>对应于$\theta^Tx​$，或者就是 $z​$ 会远小于0</li>
</ul>
</li>
</ul>
<p>让我们换一种思维</p>
<p>$h_\theta \left( x \right)=g\left(\theta^{T}X \right)​$</p>
<p> $g\left( z \right)=\frac{1}{1+e^{-z}}$</p>
<p><img src="/images/1584696526870.png" alt="1584696526870"></p>
<p>类似于上面的例子，每一组数据都会为cost function增加一项，对与总的cost function，我们会将所有的训练集提供的项求和，并乘以$\frac{1}{m}​$</p>
<p>现在先忽略$\frac{1}{m}​$这一项，一起来考虑两种情况：</p>
<ul>
<li><p>$y=1$</p>
<ul>
<li><p>cost function中只有第一项（$y^{(i)}\log ( {h_\theta}(x^{(i)})​$）起作用</p>
</li>
<li><p>因此，当在 $y=1$ 时，得到下面这张图</p>
<p><img src="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B5%5D.png" alt="img"></p>
</li>
<li><p>该图显示了在给定 $z$ 的情况下 y = 1时示例的成本贡献</p>
<ul>
<li>因此，如果z大，则cost低——这很好！</li>
<li>如果z为0或负数，则cost贡献较高</li>
<li>This is why, when logistic regression sees a positive example, it tries to set $\theta^T x​$ to be a very large term</li>
</ul>
</li>
</ul>
</li>
<li><p>$y=0$</p>
<ul>
<li>cost function中只有第二项$\left( 1-y^{(i)} \right)\log \left( 1-h_\theta\left(x^{(i)} \right) \right)​$起作用</li>
<li>同上得到下图：</li>
</ul>
<p><img src="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B6%5D.png" alt="img"></p>
<ul>
<li>如果z小则cost低</li>
<li>但是如果z大，那么cost就很大</li>
</ul>
</li>
</ul>
<p><strong>Logistic回归成本函数的SVM成本函数</strong></p>
<p>要构建SVM，我们必须重新定义成本函数，我们以上面的两张图为基础：</p>
<ul>
<li><p>$y=1​$</p>
<ul>
<li>取$y=1​$的函数并创建一个新的cost function</li>
<li>代替旧的cost function曲线，创建两条直线（洋红色），它们近似于逻辑回归y = 1函数</li>
</ul>
<p><img src="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B7%5D.png" alt="img"></p>
<ul>
<li>在z轴上取点（1）<ul>
<li>从这个点斜率 = 0</li>
</ul>
</li>
<li>这意味着新的曲线是由两条直线组合而成</li>
<li>所以这是新的y = 1 cost function<ul>
<li>使SVM具有计算优势和更轻松的优化问题</li>
<li>我们称此cost function为：$cost_1(z)$</li>
</ul>
</li>
</ul>
</li>
<li><p>$y=0$</p>
<ul>
<li>用y = 0函数图做等效项</li>
</ul>
<p><img src="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B8%5D.png" alt="img"></p>
<ul>
<li>我们称此cost function为：$cost_2(z)$</li>
</ul>
</li>
</ul>
<p><strong>完整的 SVM cost function</strong></p>
<p><img src="/images/1584696618394.png" alt="1584696618394"></p>
<p><strong>表示方法不同处</strong></p>
<ul>
<li><p>除去$1/m​$这一项</p>
<ul>
<li>去除这一项并不会导致得出的参数出现变化</li>
</ul>
</li>
<li><p>对于逻辑回归的两个条件</p>
<ul>
<li>训练数据集项（$[y^{(i)}cost_1 \left(\theta^Tx^{(i)}) \right)+\left( 1-y^{(i)} \right)cost_0\left(\theta^Tx^{(i)}) \right]​$）=  <strong>A</strong></li>
<li>正则化项（$\frac{1}{2}\sum\limits_{i=1}^{n}\theta^2_j​$）= B<ul>
<li>因此我们可以将其描述为A +  λB</li>
<li>需要某种方式来处理正则化项和训练样本的代价之间的平衡</li>
<li>为λ设置不同的值  以参数化找到这个最好的拟合</li>
</ul>
</li>
<li>参数化为  A +  λB 替换<ul>
<li><strong>对于SVM，约定是使用另一个称为C的参数</strong></li>
<li>CA + B也是如此</li>
<li>如果C等于1 / λ，那么两个函数（CA + B和A +  λB）  将给出相同的值</li>
</ul>
</li>
</ul>
</li>
<li><p>我们最后得到的等式是：$minC\sum\limits_{i=1}^m{[y^{(i)}cost_1 \left(\theta^Tx^{(i)}) \right)+\left( 1-y^{(i)} \right)cost_0\left(\theta^Tx^{(i)}) \right]}+\frac{1}{2}\sum\limits_{i=1}^n\theta^2_j​$</p>
</li>
<li><p>对于假设函数 $h_\theta(x) = 1 \ \ if\ \theta^Tx\ge0​$</p>
<p>​                $h_\theta(x) = 0 \ \ others$</p>
</li>
</ul>
<h3 id="12-2-大边界的直观理解（Large-margin-intuition）"><a href="#12-2-大边界的直观理解（Large-margin-intuition）" class="headerlink" title="12.2 大边界的直观理解（Large margin intuition）"></a>12.2 大边界的直观理解（Large margin intuition）</h3><p>人们有时将<strong>支持向量机</strong>称为<strong>大间距分类器</strong></p>
<p><img src="http://www.holehouse.org/mlclass/12_Support_Vector_Machines_files/Image%20%5B12%5D.png" alt="img"></p>
<p>上图中我们画出了${\cos}t_1{(z)}$和${\cos}t_0{(z)}​$</p>
<p>现在让我们考虑一下，最小化这些代价函数的必要条件是什么</p>
<ul>
<li><p>If y =1</p>
<ul>
<li>${\cos}t_1{(z)}$ = 0 only when z &gt;= 1</li>
</ul>
</li>
<li><p>If y = 0</p>
<ul>
<li>${\cos}t_0{(z)}​$ = 0 only when z &lt;= -1</li>
</ul>
</li>
<li><p>这里面有一个有趣的地方</p>
<ul>
<li>如果你有一个正样本$y=1​$，则其实我们仅仅要求 $z​$ 大于等于0，就能将该样本恰当的分类</li>
<li>类似地，如果你有一个负样本，则仅需要总$z$ &lt;=0就会将负例正确分类</li>
<li>但是，支持向量机的要求更高，不仅仅要能正确分开输入的样本，即不仅仅要求 $z$ &gt;0，我们需要的是比0值大很多，比如大于等于1，我也想这个比0小很多，比如我希望它小于等于-1</li>
<li>也就是说需要在支持向量机中嵌入了一个<strong>额外的安全因子</strong></li>
</ul>
</li>
</ul>
<p><strong>我们想知道，在SVM中，这个因子会导致什么结果</strong></p>
<p><img src="/images/1584696727001.png" alt="1584696727001"></p>
<p>我们接下来会考虑一个特例：将这个常数C设置成一个非常大的值</p>
<p>如果 $C$非常大，则最小化代价函数的时候，我们将会很希望找到一个使第一项(中括号内)为0的最优解。</p>
<p>我们已经看到输入一个训练样本标签为$y=1$，你想令${\cos}t_1{(z)}$为0，你需要做的是找到一个$$，使得$\theta^Tx&gt;=1$；类似地，对于一个训练样本，标签为$y=0$，为了使${\cos}t_0{(z)}$ 函数的值为0，我们需要$\theta^Tx&lt;=-1$</p>
<p><strong>我们要在同时满足上面的$y=1$和$y=0$的情况下找到能使第一项A为0的参数$\theta$</strong></p>
<p>现在考虑我们的优化问题</p>
<p>由于第一项(A)等于0，所以我们可以将这一项删去，我们所需要最小化的部分也发生了变化</p>
<p>$min\frac{1}{2}\sum\limits_{i=1}^{n}\theta^2_j​$<br>遵从：$\theta^Tx^{(i)}&gt;=1​$，如果 $y^{(i)}=1​$</p>
<pre><code>$\theta^Tx^{(i)}&lt;=-1$，如果 $y^{(i)}=0$</code></pre><p>现在我们来求解这个优化问题的时候，会得到一个十分有趣的决策边界<br><img src="https://img-blog.csdnimg.cn/20200216202054167.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MDgyMTQ4,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<ul>
<li>绿线和品红色线是可以通过逻辑回归选择的功能决策边界，<ul>
<li>但是他们可能没有很好地分类数据</li>
</ul>
</li>
<li>黑线是SVM选择的<ul>
<li>SVM是更强大的分类器</li>
</ul>
</li>
<li>数学上来讲，这是什么意思呢？这条黑线有更大的距离，这个距离叫做间距(<strong>margin</strong>)。</li>
</ul>
<p>事实上，支持向量机现在要比这个大间距分类器所体现得更成熟更复杂，尤其是当你使用大间距分类器的时候，你的学习算法会受<strong>异常点(outlier)</strong> 的影响。</p>
<p>比如我们加入一个额外的正样本<br><img src="https://img-blog.csdnimg.cn/20200216202109997.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MDgyMTQ4,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>加入异常点前我们拟合得到的使黑色的线，而加入异常点之后我们得到的使品红色的线，这样的结果显然很糟糕</p>
<p><strong>但如果你将C设置的不要太大，则你最终会得到这条黑线</strong></p>
<p>也就是说<strong>当$C$不是非常非常大的时候，它可以忽略掉一些异常点的影响，得到更好的决策界，而只有当你的数据中没有异常点并且可以轻松的线性分离数据时，才适合用SVM作为大间距分类器</strong></p>
<p>回顾 $C=1/\lambda$，因此：</p>
<p>$C$ 较大时，相当于 $\lambda$ 较小，可能会导致过拟合，高方差。</p>
<p>$C$ 较小时，相当于$\lambda$较大，可能会导致低拟合，高偏差。</p>
<p>稍后会介绍支持向量机的偏差和方差，希望在那时候关于如何处理参数的这种平衡会变得更加清晰</p>
<h3 id="12-4-核函数1：使SVM适应非线性分类器"><a href="#12-4-核函数1：使SVM适应非线性分类器" class="headerlink" title="12.4 核函数1：使SVM适应非线性分类器"></a>12.4 核函数1：使SVM适应非线性分类器</h3><p>回顾我们之前讨论过可以使用高次项的多项式模型来解决无法用直线进行分隔的分类问题：<br><img src="https://img-blog.csdnimg.cn/20200216202139908.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MDgyMTQ4,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>为了获得上图所示的判定边界，我们的模型可能是${{\theta }_{0}}+{{\theta }_{1}}{{x}_{1}}+{{\theta }_{2}}{{x}_{2}}+{{\theta }_{3}}{{x}_{1}}{{x}_{2}}+{{\theta }_{4}}x_{1}^{2}+{{\theta }_{5}}x_{2}^{2}+\cdots​$的形式。</p>
<p>我们可以用一系列的新的特征$f​$来替换模型中的每一项。例如令：<br>${{f}_{1}}={{x}_{1}},{{f}_{2}}={{x}_{2}},{{f}_{3}}={{x}_{1}}{{x}_{2}},{{f}_{4}}=x_{1}^{2},{{f}_{5}}=x_{2}^{2}​$…得到$h_θ(x)={{\theta }_{1}}f_1+{{\theta }_{2}}f_2+…+{{\theta }_{n}}f_n​$。然而，除了对原有的特征进行组合以外，有没有更好的方法来构造$f_1,f_2,f_3​$ ？（这样的构造方式在x过多时计算量太大）</p>
<p>我们可以利用<strong>核函数</strong>来计算出新的特征。</p>
<p>给定一个训练样本$x​$，我们利用$x​$的各个特征与我们预先选定的<strong>标记</strong>(<strong>landmarks</strong>)$l^{(1)},l^{(2)},l^{(3)}​$的近似程度来选取新的特征$f_1,f_2,f_3​$</p>
<p><img src="https://imgconvert.csdnimg.cn/aHR0cDovL3d3dy5ob2xlaG91c2Uub3JnL21sY2xhc3MvMTJfU3VwcG9ydF9WZWN0b3JfTWFjaGluZXNfZmlsZXMvSW1hZ2UlMjBbNDFdLnBuZw?x-oss-process=image/format,png" alt="img"></p>
<p>例如：${{f}_{1}}=similarity(x,{{l}^{(1)}})=e(-\frac{{{\left\| x-{{l}^{(1)}} \right|}^{2}}}{2{{\sigma }^{2}}})$ </p>
<pre><code>${{f}_{2}}=similarity(x,{{l}^{(2)}})=e(-\frac{{{\left\| x-{{l}^{(2)}} \right\|}^{2}}}{2{{\sigma }^{2}}})$ </code></pre><p>​       ……</p>
<p><img src="/images/1584696858952.png" alt="1584696858952"></p>
<p>上例中的$similarity(x,l^{(1)})$就是<strong>核函数</strong>（一种相似度的度量标准）</p>
<p>具体而言，这是一个<strong>高斯核函数</strong>(<strong>Gaussian Kernel</strong>)。 <strong>注：这个函数与正态分布没什么实际上的关系，只是看上去像而已。</strong></p>
<p><strong>这些标记的作用是什么？</strong></p>
<p>如果一个训练样本$x​$与地标$l​$之间的距离近似于0，则新特征 $f​$ 近似于$e^{-0}=1​$，如果训练样本$x​$与地标$l​$之间距离较远，则$f​$近似于$e^{-(一个较大的数)}=0​$。</p>
<p>假设我们的训练样本含有两个特征[$x_{1}$ $x{_2}$]，给定标记$l^{(1)}$与不同的 $\sigma$ 值，见下图：</p>
<ul>
<li>$\sigma$ 是 <strong>标准差</strong> </li>
<li>$\sigma^2​$ 通常被称为 <strong>方差</strong>，这个数值越小，标记(landmarks)周围上升的陡度越大<br><img src="https://img-blog.csdnimg.cn/20200216202218233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MDgyMTQ4,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>图中水平面的坐标为 $x_{1}​$，$x_{2}​$，而垂直坐标轴代表$f​$。可以看出，只有当$x​$与$l^{(1)}​$重合时$f​$才具有最大值。随着$x​$的改变$f​$值改变的速率受到$\sigma^2​$的控制。</li>
</ul>
<p>在下图中，假设我们已经运行了算法并获得了 $\theta$ 值</p>
<p>当样本处于<strong>品红色</strong>的点位置处，因为其离$l^{(1)}​$更近，但是离$l^{(2)}​$和$l^{(3)}​$较远，因此$f_1​$接近1，而$f_2​$,$f_3​$接近0。因此$h_θ(x)=θ_0+θ_1f_1+θ_2f_2+θ_1f_3&gt;0​$，因此预测$y=1​$。</p>
<p>对于<strong>蓝绿色</strong>的点，因为其离三个标记都较远，预测$y=0$。<br><img src="https://imgconvert.csdnimg.cn/aHR0cDovL3d3dy5ob2xlaG91c2Uub3JnL21sY2xhc3MvMTJfU3VwcG9ydF9WZWN0b3JfTWFjaGluZXNfZmlsZXMvSW1hZ2UlMjBbNDldLnBuZw?x-oss-process=image/format,png" alt="img"></p>
<p>这样，下图中红色的封闭曲线所表示的范围，便是我们依据一个单一的训练样本和我们选取的标记所得出的判定边界，在预测时，我们采用的特征不是训练样本本身的特征，而是通过核函数计算出的新特征$f_1,f_2,f_3$。</p>
<p><img src="F:%5Cworkspace%5Cpython%5C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%5C%E5%90%B4%E6%81%A9%E8%BE%BE%5Ctiantian152-Coursera-ML-AndrewNg-Notes-master%5CCoursera-ML-AndrewNg-Notes%5Cimages%5C3d8959d0d12fe9914dc827d5a074b564.jpg" alt="3d8959d0d12fe9914dc827d5a074b564"></p>
<ul>
<li><p>在内部我们预测y = 1</p>
</li>
<li><p>外面我们预测y = 0</p>
</li>
<li><p>因此，这说明了我们如何在支持向量机中创建具有界标和核函数的非线性边界</p>
</li>
</ul>
<p>但是现在这个模型仍然存在没有解决的问题</p>
<ul>
<li>我们如何获得/选择 地标</li>
<li>我们还可以使用其他哪些内核（高斯内核除外）<h3 id="12-5-核函数2"><a href="#12-5-核函数2" class="headerlink" title="12.5 核函数2"></a>12.5 核函数2</h3></li>
</ul>
<h5 id="如何选择标记-landmarks"><a href="#如何选择标记-landmarks" class="headerlink" title="如何选择标记(landmarks)"></a>如何选择标记(landmarks)</h5><p>我们通常是根据训练集的数量选择标记的数量，即如果训练集中有$m$个样本，则我们选取$m$个标记，并且令：$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},…..,l^{(m)}=x^{(m)}$。</p>
<p>这样做的好处在于：现在我们得到的新特征是建立在原有特征与训练集中所有其他特征之间距离的基础之上的，即：<img src="https://img-blog.csdnimg.cn/20200216201536961.png" alt="eca2571849cc36748c26c68708a7a5bd"></p>
<p>下面我们将核函数运用到<strong>支持向量机（SVM）</strong>中，修改我们的支持向量机假设为：</p>
<p>给定$x​$，计算新特征$f​$，当$θ^Tf&gt;=0​$ 时，预测 $y=1​$，否则反之。 </p>
<p>相应地修改代价函数为：$\sum\limits_{j=1}^{n=m}\theta _j^2=\theta^{T}\theta​$，</p>
<p><img src="/images/1584696927439.png" alt="1584696927439"><br>在具体实施过程中，我们还需要对最后的正则化项进行些微调整，在计算$\sum\limits_{j=1}^{n=m}\theta _j^2=\theta^{T}\theta$时，我们用$θ^TMθ$代替$θ^Tθ$，其中$M$是根据我们选择的核函数而不同的一个矩阵。这样做的原因是为了<strong>简化计算</strong>。</p>
<p>理论上讲，我们也可以在<strong>逻辑回归</strong>中使用核函数，但是上面使用 $M$来简化计算的方法不适用与逻辑回归，因此计算将非常耗费时间。</p>
<p>在此，我们不介绍<strong>最小化支持向量机的代价函数</strong>的方法，你可以使用现有的软件包（如<strong>liblinear</strong>,<strong>libsvm</strong>等）。在使用这些软件包最小化我们的代价函数之前，我们通常需要编写核函数，并且如果我们使用高斯核函数，那么在使用之前进行<strong>特征缩放</strong>是非常必要的。</p>
<p>另外，支持向量机也可以不使用核函数，不使用核函数又称为<strong>线性核函数</strong>(<strong>linear kernel</strong>)，当我们不采用非常复杂的函数，或者我们的训练集特征非常多而样本非常少的时候，可以采用这种不带核函数的支持向量机。</p>
<p>下面是支持向量机的两个参数$C$和$\sigma$的影响：</p>
<p>$C=1/\lambda$</p>
<p>$C$ 较大时，相当于$\lambda$较小，可能会导致过拟合，高方差；</p>
<p>$C$ 较小时，相当于$\lambda$较大，可能会导致低拟合，高偏差；</p>
<p>$\sigma$ 较大时，可能会导致低方差，高偏差，f 特征更加平稳</p>
<p>$\sigma$ 较小时，可能会导致低偏差，高方差，f 特征变化较大</p>
<p>如果你看了本周的编程作业，你就能亲自实现这些想法，并亲眼看到这些效果。这就是利用核函数的支持向量机算法，希望这些关于偏差和方差的讨论，能给你一些对于算法结果预期的直观印象。</p>
<h3 id="12-6-使用支持向量机"><a href="#12-6-使用支持向量机" class="headerlink" title="12.6 使用支持向量机"></a>12.6 使用支持向量机</h3><p>需要的东西</p>
<ul>
<li>使用SVM软件包（例如liblinear，libsvm）求解参数 $\theta$</li>
<li>需要指定一些参数<ul>
<li>参数C</li>
<li>内核<ul>
<li>高斯核函数(<strong>Gaussian Kernel</strong>)</li>
<li>线性核函数</li>
<li>多项式核函数（<strong>Polynomial Kerne</strong>l）</li>
<li>字符串核函数（<strong>String kernel</strong>）</li>
<li>卡方核函数（ <strong>chi-square kernel</strong>）</li>
<li>直方图交集核函数（<strong>histogram intersection kernel</strong>）</li>
<li>等等…</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>下面是一些普遍使用的准则：</strong></p>
<p>$n$为特征数，$m$为训练样本数。</p>
<p>(1)如果相较于$m$而言，$n$要大许多，即训练集数据量不够支持我们训练一个复杂的非线性模型，我们选用逻辑回归模型或者不带核函数的支持向量机。</p>
<p>(2)如果$n$较小，而且$m$大小中等，例如$n$在 1-1000 之间，而$m$在10-10000之间，使用高斯核函数的支持向量机。</p>
<p>(3)如果$n$较小，而$m$较大，例如$n$在1-1000之间，而$m$大于50000，则使用支持向量机会非常慢，解决方案是创造、增加更多的特征，然后使用逻辑回归或不带核函数的支持向量机。</p>
<p>值得一提的是，神经网络在以上三种情况下都可能会有较好的表现，但是训练神经网络可能非常慢，选择支持向量机的原因主要在于它的代价函数是凸函数，不存在局部最小值。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 吴恩达机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/03/20/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1/" rel="next" title="吴恩达机器学习（十一）机器学习系统的设计">
                <i class="fa fa-chevron-left"></i> 吴恩达机器学习（十一）机器学习系统的设计
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">tiantian</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7Carchive">
              
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#十二、支持向量机-Support-Vector-Machines"><span class="nav-text">十二、支持向量机 (Support Vector Machines)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#12-1-优化目标"><span class="nav-text">12.1 优化目标</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-2-大边界的直观理解（Large-margin-intuition）"><span class="nav-text">12.2 大边界的直观理解（Large margin intuition）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-4-核函数1：使SVM适应非线性分类器"><span class="nav-text">12.4 核函数1：使SVM适应非线性分类器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-5-核函数2"><span class="nav-text">12.5 核函数2</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#如何选择标记-landmarks"><span class="nav-text">如何选择标记(landmarks)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-6-使用支持向量机"><span class="nav-text">12.6 使用支持向量机</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">tiantian</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2020/03/20/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/';
          this.page.identifier = '2020/03/20/吴恩达机器学习（十二）支持向量机SVM/';
          this.page.title = '吴恩达机器学习（十二）支持向量机SVM';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
